---
title: "Data Preprocessing"
mainfont: UnDotum
monofont: UnShinmun
author: "Park Ju ho"
date: '2022 4 11 '
output:
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(caret)
```

```{r}
data(mdrr)
data.frame(table(mdrrDescr$nR11))
```
# 영분산 측정
freqRatio = 일 순위 빈발값의 빈도/차 순위 빈발값의 빈도
=> 정상적일 수록 1에 가깝고 클수록 불균형

percentUnique = 유일한 값들의 수/전체 표본 수
=> 0에 가까울 수록 영분산

nearZeroVar에선 유일 값 비율이 10%, 빈도비율이 19보다 큰 예측 변수를 영분산이로 간주
```{r}
nzv = nearZeroVar(mdrrDescr,saveMetrics = TRUE)
#saveMetrics를 통하여 각 예측값에 대한 빈도비 율과 유일 값들의 비율을 얻을 수 있음
str(nzv)
nzv[nzv$nzv,]#0분산인 애들 모음

dim(mdrrDescr)
nzv = nearZeroVar(mdrrDescr)#saveMetrics가 아니기에 index만 반환
nzv
filteredDescr <- mdrrDescr[, -nzv]
dim(filteredDescr)
```
# 중복 변수 제거
```{r}
descrCor = cor(filteredDescr)
sum(abs(descrCor[upper.tri(descrCor)])>.999)
#상관계수로 이루어진 상삼각렬을 구한 뒤 상관계수가 0.999이상인 것의 수

summary(descrCor[upper.tri(descrCor)])

higlyCorDescr = findCorrelation(descrCor,cutoff=0.75)
higlyCorDescr
#상관계수가 0.75인 변수 추출
filteredDescr = filteredDescr[,-higlyCorDescr]
#높은 상관계수 변수들 제거
descrCor2 = cor(filteredDescr)
summary(descrCor2[upper.tri(descrCor2)])
```
# 중심화와 척도화
```{r}
set.seed(200)
inTrain = sample(seq(along = mdrrClass), length(mdrrClass)/2)
#seq(along = ) along의 길이만큼 seq를 생성, 1:1의 비율로 Test,Train 나눔

training = filteredDescr[inTrain,]
test = filteredDescr[-inTrain,]
trainMDRR = mdrrClass[inTrain]
testMDRR = mdrrClass[-inTrain]

preProcValues = preProcess(training,method = c("center","scale"))
#객체 생성, 둘 다 진행했기 때문에 표준화임
trainTransformed = predict(preProcValues,training)
testTransformed = predict(preProcValues,test)
head(training)
head(trainTransformed)
```
# box-cox
등분산 가정을 위하여
```{r}
preProcValues2 = preProcess(training,method = "BoxCox")
trainBC = predict(preProcValues2,training)
testBC = predict(preProcValues2,test)
preProcValues2
head(training)
head(trainBC)
```
#더비변수 생성
범주형 변수를 원-핫 벡터로 바꾸는 것
```{r}
library(earth)
data(etitanic)
str(etitanic)
head(etitanic)

head(model.matrix(survived~.,data=etitanic))
#matrix를 자동적으로 dummy 변수를 만들고 학습하기 좋은 matrix를 생성
dummy.1 = dummyVars(survived~.,data=etitanic)
head(predict(dummy.1,newdata = etitanic))
```
#선형 종속성
3,1,2와 6,1,4,5들끼리 선형 종속을 이루고 있음
이를 해결하기 위하여 3번과 6번 열을 제거하면 됨
```{r}
ltfrDesign <- matrix(0, nrow = 6, ncol = 6)
ltfrDesign[, 1] <- c(1, 1, 1, 1, 1, 1)
ltfrDesign[, 2] <- c(1, 1, 1, 0, 0, 0)
ltfrDesign[, 3] <- c(0, 0, 0, 1, 1, 1)
ltfrDesign[, 4] <- c(1, 0, 0, 1, 0, 0)
ltfrDesign[, 5] <- c(0, 1, 0, 0, 1, 0)
ltfrDesign[, 6] <- c(0, 0, 1, 0, 0, 1)

comboinfo = findLinearCombos(ltfrDesign)
comboinfo
ltfrDesign[,-comboinfo$remove]
```
#결측값 대치
```{r}
library(caret)
data("airquality")
summary(airquality)
#다량의 결측치 확인
imp.1 = preProcess(airquality,method = c("knnImpute"))
#KNN 방법을 이용하여 결측값 대치
library(RANN)
imp.2 = predict(imp.1,airquality)
summary(imp.2)
#결측치가 처리된 것을 확인 할 수 있음
```
#군집거리 계산
```{r}
trainSet = sample(1:150,100)
#100:50으로 train,test분리
distData = classDist(iris[trainSet,1:4],iris$Species[trainSet])
#군집거리 계산함수
distData$values

newDist = predict(distData, iris[-trainSet,1:4])
#test data에 대한 마할라노비스 거리
head(newDist)

splom(newDist, groups = iris$Species[-trainSet], auto.key=list(columns=3))
```

















